{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceGeneratorBW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8SIudqXhn12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ag9PKrWPMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JUSb54tipfF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiGe1rcxW3sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUGiRctzW-sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYJGcmeVXQL_",
        "colab_type": "code",
        "outputId": "537f2afd-cd59-4cb9-dd5c-a7180ceda1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!kaggle datasets download -d jessicali9530/celeba-dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading celeba-dataset.zip to /content\n",
            " 99% 1.20G/1.21G [00:20<00:00, 87.9MB/s]\n",
            "100% 1.21G/1.21G [00:20<00:00, 62.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B0Pvh-fZWdt",
        "colab_type": "code",
        "outputId": "3d3f1834-ac4c-4f9c-fecb-28be40ccc2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  celeba-dataset.zip\n",
            "  inflating: list_attr_celeba.csv    \n",
            "  inflating: img_align_celeba.zip    \n",
            "  inflating: list_landmarks_align_celeba.csv  \n",
            "  inflating: list_bbox_celeba.csv    \n",
            "  inflating: list_eval_partition.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1HJkBl3af-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "d = pd.read_csv('list_attr_celeba.csv')\n",
        "d.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydtj-Oyg53-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip img_align_celeba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrKPuEojpMCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8NmZvjBeLKH",
        "colab_type": "code",
        "outputId": "ec14dcdb-23b6-4444-ba9a-109342aeff68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process(folder, dest_folder, target_shape=None, from_ending=None, to_ending=None,grayscale=False):\n",
        "      if os.path.isfile(folder):\n",
        "            try:\n",
        "                  if from_ending is None or folder.endswith(from_ending):\n",
        "                        img = Image.open(folder)\n",
        "                        if target_shape is not None:\n",
        "                              img = img.resize(target_shape)\n",
        "                        if grayscale:\n",
        "                              img = img.convert('L')\n",
        "                        if to_ending is not None:\n",
        "                              ending = to_ending\n",
        "                        else:\n",
        "                              ending = folder[folder.rfind('.'):]\n",
        "                        num_processed = len(os.listdir(dest_folder))\n",
        "                        img_name = str(num_processed) + ending\n",
        "                        img_name = os.path.join(dest_folder, img_name)\n",
        "                        img.save(img_name)\n",
        "            except Exception as e:\n",
        "                  print('Failed for file %s: %s' % (folder, str(e)))\n",
        "      elif os.path.isdir(folder):\n",
        "            files = os.listdir(folder)\n",
        "            files=files[:40000]\n",
        "            for file in tqdm(files):\n",
        "                  process(os.path.join(folder,file),\n",
        "                          dest_folder,\n",
        "                          target_shape=target_shape,\n",
        "                          from_ending=from_ending,\n",
        "                          to_ending=to_ending,\n",
        "                          grayscale=grayscale)\n",
        "      else:\n",
        "            print('ERROR: %s does not exist!' % folder)\n",
        "\n",
        "process(r'img_align_celeba',\n",
        "        r'sample',target_shape=(64,64),\n",
        "        from_ending='.jpg',\n",
        "        to_ending='.png',\n",
        "        grayscale=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40000/40000 [07:45<00:00, 86.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KdD1rTWezShX",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFj-E16xhHgL",
        "colab_type": "code",
        "outputId": "eab0435a-d686-4dbf-96b8-07426c9d5f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "img_dir = r'sample'\n",
        "files = [x for x in os.listdir(img_dir) if x[-4:] == '.png']\n",
        "dataset = np.empty((len(files),64,64,1))\n",
        "for i,file in tqdm(enumerate(files)):\n",
        "      img = Image.open(os.path.join(img_dir, file))\n",
        "      img = np.array(img)\n",
        "      if len(img.shape) > 2:\n",
        "            img = img[:,:,0]\n",
        "      dataset[i] = np.expand_dims(img,axis=2)\n",
        "np.save('dataset.npy', dataset)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000it [00:08, 4659.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNAfR8mGdhDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "874ff5fc-fa9d-47a4-a46b-b22146a68d67"
      },
      "source": [
        "ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "celeba-dataset.zip    kaggle.json              list_landmarks_align_celeba.csv\n",
            "dataset.npy           list_attr_celeba.csv     \u001b[0m\u001b[01;34msample\u001b[0m/\n",
            "\u001b[01;34mimg_align_celeba\u001b[0m/     list_bbox_celeba.csv     \u001b[01;34msample_data\u001b[0m/\n",
            "img_align_celeba.zip  list_eval_partition.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr1Ru3lxtqpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def rescale(data, min_num, max_num, data_min=None, data_max=None):\n",
        "      if data_min is None:\n",
        "            data_min = np.min(data)\n",
        "      if data_max is None:\n",
        "            data_max = np.max(data)\n",
        "      data_range = data_max - data_min\n",
        "      data = ((data - data_min) / data_range) * (max_num - min_num) + min_num\n",
        "      return data\n",
        "\n",
        "def write_log(callback, names, logs, epoch):\n",
        "      import tensorflow as tf\n",
        "      \"\"\"Write stats to TensorBoard\"\"\"\n",
        "      for name, value in zip(names, logs):\n",
        "        summary = tf.Summary()\n",
        "        summary_value = summary.value.add()\n",
        "        summary_value.simple_value = value\n",
        "        summary_value.tag = name\n",
        "        callback.writer.add_summary(summary, epoch)\n",
        "        callback.writer.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ea6PaSPhJ8B",
        "colab_type": "code",
        "outputId": "cb3b47d2-e1db-4586-ff8d-2f6eae984a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, GaussianNoise, LeakyReLU, Dropout\n",
        "from keras.layers import BatchNormalization, Flatten, Dense, Activation\n",
        "from keras.layers import Conv2DTranspose, Input, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "import os\n",
        "from datetime import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "np.random.seed(26)\n",
        "\n",
        "image_shape = (64,64,1)\n",
        "noise_shape = (100,)\n",
        "\n",
        "def build_discriminator():\n",
        "      discriminator = Sequential()\n",
        "      discriminator.add(GaussianNoise(0.01, input_shape=image_shape))\n",
        "      discriminator.add(Conv2D(64, kernel_size=3, strides=1, padding='same'))\n",
        "      discriminator.add(LeakyReLU(alpha=0.01))\n",
        "      discriminator.add(Dropout(0.5))\n",
        "      \n",
        "      discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "      discriminator.add(BatchNormalization())\n",
        "      discriminator.add(LeakyReLU(alpha=0.01))\n",
        "      discriminator.add(Dropout(0.5))\n",
        "      \n",
        "      discriminator.add(Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
        "      discriminator.add(BatchNormalization())\n",
        "      discriminator.add(LeakyReLU(alpha=0.01))\n",
        "      discriminator.add(Dropout(0.5))\n",
        "      \n",
        "      discriminator.add(Conv2D(512, kernel_size=3, strides=2, padding='same'))\n",
        "      discriminator.add(BatchNormalization())\n",
        "      discriminator.add(LeakyReLU(alpha=0.01))\n",
        "      discriminator.add(Dropout(0.5))\n",
        "      \n",
        "      discriminator.add(Conv2D(1024, kernel_size=3, strides=2, padding='same'))\n",
        "      discriminator.add(BatchNormalization())\n",
        "      discriminator.add(LeakyReLU(alpha=0.01))\n",
        "      discriminator.add(Dropout(0.5))\n",
        "      \n",
        "      discriminator.add(Flatten())\n",
        "      discriminator.add(Dense(1))\n",
        "      discriminator.add(Activation('sigmoid'))\n",
        "      return discriminator\n",
        "\n",
        "def build_generator():\n",
        "      generator = Sequential()\n",
        "      generator.add(Dense(8*8*1024, input_shape=noise_shape))\n",
        "      generator.add(Reshape((8,8,1024)))\n",
        "      generator.add(BatchNormalization())\n",
        "      generator.add(LeakyReLU(alpha=0.01))\n",
        "      \n",
        "      generator.add(Conv2DTranspose(512, kernel_size=3, strides=2, padding='same'))\n",
        "      generator.add(BatchNormalization())\n",
        "      generator.add(LeakyReLU(alpha=0.01))\n",
        "      \n",
        "      generator.add(Conv2DTranspose(256, kernel_size=3, strides=2, padding='same'))\n",
        "      generator.add(BatchNormalization())\n",
        "      generator.add(LeakyReLU(alpha=0.01))\n",
        "      \n",
        "      generator.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "      generator.add(BatchNormalization())\n",
        "      generator.add(LeakyReLU(alpha=0.01))\n",
        "      \n",
        "      generator.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "      generator.add(BatchNormalization())\n",
        "      generator.add(LeakyReLU(alpha=0.01))\n",
        "      \n",
        "      generator.add(Conv2DTranspose(1,kernel_size=3, strides=1, padding='same'))\n",
        "      generator.add(Activation('tanh'))\n",
        "      return generator\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "generator = build_generator()\n",
        "\n",
        "# Create optimizers\n",
        "d_optimizer = Adam(lr=0.0005, beta_1=0.3)\n",
        "g_optimizer = Adam(lr=0.0005, beta_1=0.3)\n",
        "\n",
        "# Compile and setup discriminator\n",
        "discriminator.compile(d_optimizer, loss='binary_crossentropy')\n",
        "discriminator.trainable = False\n",
        "#true doesnt give good results\n",
        "\n",
        "noise_input = Input(shape=noise_shape)\n",
        "generated_image = generator(noise_input)\n",
        "validity = discriminator(generated_image)\n",
        "\n",
        "# Build and compile a combined model\n",
        "combined = Model(noise_input, validity)\n",
        "combined.compile(optimizer=g_optimizer, loss='binary_crossentropy')\n",
        "\n",
        "epochs = 10\n",
        "batch_size=32\n",
        "half_batch = batch_size//2\n",
        "\n",
        "if not os.path.isdir('logs/facev2'):\n",
        "      os.makedirs('logs/facev2')\n",
        "\n",
        "# Init TensorBoard callback\n",
        "date = datetime.today().strftime('%m-%d_%H%M')\n",
        "callback = TensorBoard(os.path.join('logs/facev2',date))\n",
        "callback.set_model(combined)\n",
        "train_names = ['g_loss', 'd_loss']\n",
        "\n",
        "# Make checkpoint directory\n",
        "if not os.path.isdir('checkpoints/facev2/%s' % date):\n",
        "      os.makedirs('checkpoints/facev2/%s' % date)\n",
        "\n",
        "# Make image directory\n",
        "if not os.path.isdir('generated_images/facev2/%s' % date):\n",
        "      os.makedirs('generated_images/facev2/%s' % date)\n",
        "\n",
        "write_image_period = 1 # Write images every 20 epochs\n",
        "num_images_to_write = 10 # Generate 10 images\n",
        "\n",
        "# adding random loss\n",
        "best_g_loss = math.inf\n",
        "\n",
        "DATASET_PATH = r'sample'\n",
        "all_images = os.listdir(DATASET_PATH)\n",
        "num_images = len([img for img in all_images if img.endswith('.png')])\n",
        "\n",
        "def get_batch(batch_size):\n",
        "      image_indexes = np.random.randint(0, len(all_images), batch_size)\n",
        "      images = np.array([np.expand_dims(np.array(Image.open(os.path.join(DATASET_PATH,all_images[i]))),axis=2) for i in image_indexes])\n",
        "      return rescale(images.astype(np.float32), -1, 1, data_min=0, data_max=255)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "      losses = []\n",
        "      for _ in tqdm(range(num_images // batch_size)):\n",
        "            # Train discriminator\n",
        "            \n",
        "            # Get random valid images\n",
        "            images = get_batch(half_batch)\n",
        "            \n",
        "            # Generate random invalid images\n",
        "            noises = np.random.uniform(-1, 1, size=(half_batch, *noise_shape))\n",
        "            generated_images = generator.predict(noises)\n",
        "            \n",
        "            # Train on each half batch\n",
        "            # Invalid images' ground truth is zeros\n",
        "            discriminator_loss_fake = discriminator.train_on_batch(generated_images, np.zeros((half_batch,1)))\n",
        "            # Valid images' ground truth is ones\n",
        "            discriminator_loss_real = discriminator.train_on_batch(images, np.ones((half_batch,1))*0.9)\n",
        "            discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "            \n",
        "            # Train generator\n",
        "            \n",
        "            # Create noise to generate images\n",
        "            noises = np.random.uniform(-1, 1, size=(batch_size, *noise_shape))\n",
        "            \n",
        "            # Train using the combined model, since the error relies on the discriminator\n",
        "            generator_loss = combined.train_on_batch(noises, np.ones((batch_size, 1)))\n",
        "            \n",
        "            # Add to list of losses\n",
        "            losses.append((generator_loss, discriminator_loss))\n",
        "      # Calculate losses and accuracies\n",
        "      avg_g_loss = np.average([loss[0] for loss in losses])\n",
        "      avg_d_loss = np.average([loss[1] for loss in losses])\n",
        "      \n",
        "      noises = np.random.uniform(-1, 1, size=(half_batch, *noise_shape))\n",
        "      generated_images = generator.predict(noises)\n",
        "      \n",
        "      if epoch % write_image_period == 0:\n",
        "            for i,img in enumerate(generated_images[:num_images_to_write]):\n",
        "                  image = rescale(img.squeeze(), 0, 255, data_min=-1, data_max=1)\n",
        "                  image = Image.fromarray(np.round(image).astype(np.uint8))\n",
        "                  image.save('generated_images/facev2/%s/epoch%03d_%d.png'%(date,epoch,i))\n",
        "      \n",
        "      try:\n",
        "            generator.save('checkpoints/facev2/{}/g_epoch{:04d}.h5'.format(date, epoch))\n",
        "            discriminator.save('checkpoints/facev2/{}/d_epoch{:04d}.h5'.format(date, epoch))\n",
        "            best_g_loss = avg_g_loss\n",
        "      except:\n",
        "            pass\n",
        "      # Write log to TensorBoard\n",
        "      write_log(callback, train_names, [avg_g_loss, avg_d_loss], epoch)\n",
        "      # Print to console\n",
        "      print('Epoch: {: 5d} [G loss: {: 10.6f}] [D loss: {: 10.6f}]'.format(epoch, avg_g_loss, avg_d_loss))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1250 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "  0%|          | 1/1250 [00:10<3:42:07, 10.67s/it]/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "100%|██████████| 1250/1250 [04:40<00:00,  4.49it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     0 [G loss:   0.406078] [D loss:   0.356367]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:37<00:00,  4.49it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     1 [G loss:   0.198986] [D loss:   0.302061]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:36<00:00,  4.49it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     2 [G loss:   0.211829] [D loss:   0.249492]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:36<00:00,  4.53it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     3 [G loss:   0.254238] [D loss:   0.239599]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:37<00:00,  4.52it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     4 [G loss:   0.296136] [D loss:   0.228958]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:37<00:00,  4.50it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     5 [G loss:   0.171609] [D loss:   0.222242]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:38<00:00,  4.49it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     6 [G loss:   0.267865] [D loss:   0.200084]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:37<00:00,  4.51it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     7 [G loss:   0.153749] [D loss:   0.196809]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:37<00:00,  4.49it/s]\n",
            "  0%|          | 0/1250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     8 [G loss:   0.267871] [D loss:   0.234816]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1250/1250 [04:37<00:00,  4.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:     9 [G loss:   0.312727] [D loss:   0.232052]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8xJb899iFwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a418022f-4ad0-4f7d-8e78-00fad80c79ba"
      },
      "source": [
        "ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "celeba-dataset.zip  img_align_celeba.zip     list_landmarks_align_celeba.csv\n",
            "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/        kaggle.json              \u001b[01;34mlogs\u001b[0m/\n",
            "dataset.npy         list_attr_celeba.csv     \u001b[01;34msample\u001b[0m/\n",
            "\u001b[01;34mgenerated_images\u001b[0m/   list_bbox_celeba.csv     \u001b[01;34msample_data\u001b[0m/\n",
            "\u001b[01;34mimg_align_celeba\u001b[0m/   list_eval_partition.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BqmSx6f4um3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/generated_images.zip /content/generated_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQKkY3K66XB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('generated_images.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCjxePtvfLLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}